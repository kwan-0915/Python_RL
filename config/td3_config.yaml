# utility parameters
mode: train
env_name: LunarLanderContinuous-v2
device: cuda
capacity: 1000000         # Replay buffer size

# hyper parameters
start_timesteps: 25000    # Time steps initial random policy is used
eval_freq: 5000           # How often (time steps) we evaluate
max_episode: 50           # Max time steps to run environment
exploration_noise: 0.1    # Std of Gaussian exploration noise
batch_size: 256           # Batch size for both actor and critic
discount: 0.99            # Discount factor
tau: 0.005                # Target network update rate
policy_noise: 0.2         # Noise added to target policy during critic update
noise_clip: 0.5           # Range to clip target policy noise
policy_freq: 2            # Frequency of delayed policy updates

#optional parameters
seed: False
random_seed: 9527
render: False             # Show UI or not
load: False
render_interval: 100      # After render_interval, the env.render() will work
log_interval: 50
print_log: 5

